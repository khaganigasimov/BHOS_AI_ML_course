{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc36ff96",
   "metadata": {},
   "source": [
    "<h1>Importing All Necessary Modules</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "## For cloning\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9c59a",
   "metadata": {},
   "source": [
    "<h1>Data Preparation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8e8a83",
   "metadata": {},
   "source": [
    "You are given a dataset and data preparations steps were readily provided in next cells except for reading part. Run all of them to save time after uploading dataset to notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first = True)\n",
    "\n",
    "## in my case, get dummies return boolean data types. Therefore, I used the following. \n",
    "## If your pandas is latest version, you can uncomment it.\n",
    "# df.iloc[:, -6:] = df.iloc[:, -6:].astype(np.int64)\n",
    "\n",
    "df.rename({'satisfaction_satisfied': 'satisfaction'}, axis = 1, inplace = True)\n",
    "\n",
    "cols = ['Online boarding', 'Inflight entertainment', 'Seat comfort', 'On-board service', 'Leg room service', 'Cleanliness', 'Flight Distance',  'Inflight wifi service', 'Baggage handling', 'Inflight service', 'Checkin service', 'Food and drink', 'Ease of Online booking', 'Age', 'Class_Eco Plus', 'Customer Type_disloyal Customer', 'Type of Travel_Personal Travel', 'Class_Eco', 'satisfaction']\n",
    "cols_for_scaling = ['Age', 'Flight Distance']\n",
    "\n",
    "df = df[cols]\n",
    "X = df.drop('satisfaction', axis = 1)\n",
    "y = df['satisfaction']\n",
    "\n",
    "ss = StandardScaler().fit(X[cols_for_scaling])\n",
    "X[cols_for_scaling] = ss.transform(X[cols_for_scaling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b390a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "938c5211",
   "metadata": {},
   "source": [
    "<h1>Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120e67d",
   "metadata": {},
   "source": [
    "Split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd1fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60424b80",
   "metadata": {},
   "source": [
    "Call three models - LogisticRegression, LinearSVC with default parameters, and LinearSVC with different parameter, such as C = 10. Train them separately and see their scores on test dataset. Note that LinearSVC is time consuming model but faster than SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e93a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa42c01",
   "metadata": {},
   "source": [
    "Your next task is to combine them into a set of models and fit voting classifier. Use hard voting since linear svc doesn't provide probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76930c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [('lscv', LinearSVC(C = 1)),\n",
    "        ('lscv_C_10', (LinearSVC(C = 10))),\n",
    "         ('log', LogisticRegression())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adb3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad4a27b1",
   "metadata": {},
   "source": [
    "Combine n different KNeighborsClassifier and fit them with VotingClassifier. This time you can benefit from soft voting approach. Try to use low number of models since KNeighborsClassifier is time consuming. Note that less number of neighbors will mostly result in probabilities of 0 and 1 for this dataset instead of float value. So, try to use two-digit value for n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e95bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f57d5bf4",
   "metadata": {},
   "source": [
    "Now, train all KNN models and get probabilities for each. After that, obtain average probabilities and use this result for your predictions, accuracy of which is also expected to be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f9cee09",
   "metadata": {},
   "source": [
    "Make your forest! Bagging or Pasting is the sampling technique behind Random Forest Approach. Now, your task is to create BaggingClassifier with the estimator of DecisionTreeClassifier and train it. Set bootstrap as True first then check the results with False option to compare. In case of True, the model will take samples with replacement (bagging), whereas False indicates without replacement (pasting). Please, include random_state option so that scores can also be compared with RandomForestClassifier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f9b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5727ffa9",
   "metadata": {},
   "source": [
    "Additionally, train individual DecisionTreeClassifier to see how results changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a89a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43d95c8c",
   "metadata": {},
   "source": [
    "Train RandomForestClassifier with previous parameters of both bagging and decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0feecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f3b64f9",
   "metadata": {},
   "source": [
    "XGBoost is highly advanced and complicated model (also one of most favorites among ML community) thanks to special features - boosting. In the following, you will see the code with some parameters. Get familiar with documentation of xgboost and explore new parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b693edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "xgbc = XGBClassifier(max_depth = 10,\n",
    "                     eval_metric = log_loss, ## By default, metric is log_loss\n",
    "                     early_stopping_rounds = None, \n",
    "                     n_jobs = -1)\n",
    "xgbc.fit(X_train, y_train, \n",
    "         eval_set = [(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xgbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8090f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
