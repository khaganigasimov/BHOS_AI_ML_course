{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef872b1c",
   "metadata": {},
   "source": [
    "<h1>Importing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10c1ee",
   "metadata": {},
   "source": [
    "Importing all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646345e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170c8bab",
   "metadata": {},
   "source": [
    "<h1>Data Preparation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96559a79",
   "metadata": {},
   "source": [
    "You are given datasets of breast-cancer-wisconsin and diabetes. Apply some data analysis on both, such as checking shape, dtypes, missing data and then prepare your data for modeling. It is better not to waste time with finding outliers for now but you can work on this dataset at home for more advanced data preparation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47cd15",
   "metadata": {},
   "source": [
    "PS: Check value_counts for target columns of both dataset as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51eee3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0f9a5d",
   "metadata": {},
   "source": [
    "<h1>Modeling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569ce77",
   "metadata": {},
   "source": [
    "The following describes some parameters for DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c05df4",
   "metadata": {},
   "source": [
    "criterion - How you want to measure impurity of each node and leaf? Gini, Entropy, or Log-Loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4abdc6b",
   "metadata": {},
   "source": [
    "max_depth - How many depths you want for construction of tree at maximum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8211da6",
   "metadata": {},
   "source": [
    "min_samples_split - How many samples you want inside each node at minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17116435",
   "metadata": {},
   "source": [
    "min_samples_leaf - How many samples you want inside each leaf at minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f923b7",
   "metadata": {},
   "source": [
    "max_leaf_nodes - How many leaves you want for your tree at maximum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f14e6",
   "metadata": {},
   "source": [
    "min_impurity_decrease - How much impurity change you want at minimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f081d",
   "metadata": {},
   "source": [
    "min_weight_fraction_leaf - How much weight you want at each leaf at minimum ? weight = number of samples / total number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d7cbfa",
   "metadata": {},
   "source": [
    "max_features - How many features you want at each node?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f70f0",
   "metadata": {},
   "source": [
    "class_weight - How much weight you want for each class? (This is used in case of high imbalance between numbers of samples in each class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3e592",
   "metadata": {},
   "source": [
    "ccp_alpha - Which brand would you like to eliminate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015d0fe",
   "metadata": {},
   "source": [
    "Initially, we use breast-cancer-wisconsin dataset to have a better understanding of tree structure more comfortably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f391546",
   "metadata": {},
   "source": [
    "In this task, you are going plot tree with fitted model of Decision Tree Classifier. Start with default parameters for modeling and use plot_tree method to analyze your tree. Include the parameters of **feauture_names** as your column names and **filled** as True. Furthermore, use plt.savefig to save the plot in your computer and call plt.figure function to define dpi parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88297eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split your dataset and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99afb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi = 300)\n",
    "\n",
    "\n",
    "## Plot your tree\n",
    "\n",
    "\n",
    "plt.savefig('structure_of_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f93cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bec1171",
   "metadata": {},
   "source": [
    "Our tree is very complicated and hard to interpret. To understand what is happening in tree, you can zoom in so that you might see details or you would create a simpler tree structure by defining parameters of max_depth = 3, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cf1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1f8fa1",
   "metadata": {},
   "source": [
    "Your next task is to define parameters of max_depth, max_leaf_nodes, and criterion as different values and see changes while plotting the tree. Try to choose small values such as 1-5 for maximum depth, 1-10 for max_leaf_nodes, etc. You can play around the other parameters for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc81156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebe6c61c",
   "metadata": {},
   "source": [
    "The rest of tutorial will be about diabetes_prediction_dataset.csv with which we will have better understanding of overfitting in Decision Trees. If you haven't done any data prepation steps for this dataset, do it now and finish your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bb866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26a47607",
   "metadata": {},
   "source": [
    "After modeling, check your scores on both train and test dataset. Probably, you will have score over 0.90 with default parameters but do you think it is so good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fedd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2026970",
   "metadata": {},
   "source": [
    "Unfortunately, the model still overfits. To understand why, read the next cells and run the cell of decision boundary code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fb8cb",
   "metadata": {},
   "source": [
    "Cols contain two most important features affecting target column. The aim is to plot decision boundaries for given these features by fitting on train dataset and predicting on test dataset with **default** parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b07ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Choosing two most important features\n",
    "cols = ['blood_glucose_level', 'HbA1c_level']\n",
    "\n",
    "## Display Method\n",
    "display = DecisionBoundaryDisplay\n",
    "\n",
    "## Fitting\n",
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(X_train[cols], y_train)\n",
    "\n",
    "\n",
    "## Plotting Decision Boundaries\n",
    "display.from_estimator(\n",
    "    dtr,\n",
    "    X_test[cols],\n",
    "    response_method = 'predict',\n",
    "    xlabel = cols[0],\n",
    "    ylabel = cols[1],\n",
    "    alpha = 0.5    \n",
    ")\n",
    "\n",
    "## Plotting Data Points\n",
    "plt.scatter(X_test[cols[0]], X_test[cols[1]], c = y_test.values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a4fae",
   "metadata": {},
   "source": [
    "Purple data points indicate there is no diabete detected while yellow is for reverse case. It is clearly seen from the plot that yellow points have passed decision boundaries however, there is not any misprediction for non-diabete cases - purple data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05dc089",
   "metadata": {},
   "source": [
    "The model obviously overfits for cases of having diabetes. Why? Remember value_counts()? It showed us that 91500 samples of data belongs to 0 class - no diabete while only 8500 - only 8.5% of target column is about 1 class. The model would learn 0 class really well, however, lack of information about 1 class paves the way for bad fitting for only this class. To analyze such cases, it is recommended to have information about precision, recall, f1_score although it is out of the scope for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c30e7",
   "metadata": {},
   "source": [
    "How to fix this issue? Use class_weight = 'balanced' and play around with other parameters if there is still overfitting. You can also check ccp_alpha parameter to see if it can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a50d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace51fe3",
   "metadata": {},
   "source": [
    "<h1>Optional Homework</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b113e4e",
   "metadata": {},
   "source": [
    "Create a function computing gini index for given input. The input can be list, array, pandas series objects, etc. Therefore, it is better to convert them inside the function by using the method of np.asarray() which converts each container-like objects to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5607597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42035532",
   "metadata": {},
   "source": [
    "Do the same for entropy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df511b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65b36904",
   "metadata": {},
   "source": [
    "Create a function computing Information Gain based on the metric - entropy or gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7db3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "883efbe6",
   "metadata": {},
   "source": [
    "Apply the functions you created on the dataset. For example, you can define threshold of 200 for blood_glucose_level and see gini index or entropy in your new nodes combined with Information Gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387a071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
